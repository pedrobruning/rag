{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\Documents\\Projects\\AI\\scoras-academy\\rag\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is governed by the Brazilian Football Confederation (CBF). The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave\n",
      "is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower. The Eiffel Tower\n",
      "is the oldest of the Seven Wonders of the Ancient World, and the only one still in existence. The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel\n",
    "import faiss\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# RAG Examples\n",
    "\n",
    "documents = [\n",
    "    \"The Brazil national football team is the national team of Brazil and is governed by the Brazilian Football Confederation (CBF).\",\n",
    "    \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\",\n",
    "    \"The Great Pyramid of Giza is a pyramid located in the Giza pyramid complex in Egypt. It is the oldest of the Seven Wonders of the Ancient World, and the only one still in existence.\",\n",
    "]\n",
    "\n",
    "# Doc vectorizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "document_embeddings = embed(documents)\n",
    "\n",
    "# FAISS Index\n",
    "index = faiss.IndexFlatL2(document_embeddings.shape[1])\n",
    "index.add(document_embeddings)\n",
    "\n",
    "# Generative Model\n",
    "model_name = \"t5-small\"\n",
    "generator_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "generator_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# RAG method\n",
    "def rag_query(query, top_k=3):\n",
    "    # Embedding the query\n",
    "    query_embedding = embed([query])\n",
    "    \n",
    "    # Search for the most similar documents\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # Get the most similar documents\n",
    "    most_similar_documents = [documents[i] for i in indices[0]]\n",
    "\n",
    "    # Concat most similar documents with the query\n",
    "    context = \"\\n\".join(most_similar_documents) + \"\\n\\n\" + query\n",
    "\n",
    "    # Generate the response\n",
    "    inputs = generator_tokenizer.encode(context, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "    outputs = generator_model.generate(inputs, max_length=50, num_beams=2)\n",
    "    answer = generator_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example of usage\n",
    "\n",
    "question = \"What is the name of the federation that governs the Brazil national football team?\"\n",
    "print(rag_query(question))\n",
    "\n",
    "question = \"What is the name of the engineer who designed the Eiffel Tower?\"\n",
    "print(rag_query(question))\n",
    "\n",
    "question = \"What is the name of the oldest of the Seven Wonders of the Ancient World?\"\n",
    "print(rag_query(question))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
